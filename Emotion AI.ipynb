{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df = pd.read_csv('KeyFacialPoints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since values for the image is given as space separated string, we will need to separate the values using ' ' as separator.\n",
    "# Then convert this into numpy array using np.fromstring and convert the obtained 1D array into 2D array of shape (96,96)\n",
    "# 0 means black pixel 255 means white\n",
    "facialpoints_df['Image'] = facialpoints_df['Image'].apply(lambda x: np.fromstring(x, dtype= int, sep = ' ').reshape(96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's obtain the shape of the resized image\n",
    "facialpoints_df['Image'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm that there are no null values \n",
    "facialpoints_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random image from the dataset along with facial keypoints. \n",
    "i = np.random.randint(1, len(facialpoints_df))\n",
    "plt.imshow(facialpoints_df['Image'][i],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The (x, y) coordinates for the 15 key features are plotted on top of the image\n",
    "# Below is a for loop starting from index = 1 to 32 with step of 2\n",
    "# In the first iteration j would be 1, followed by 3 and so on.\n",
    "# since x-coordinates are in even columns like 0,2,4,.. and y-coordinates are in odd columns like 1,3,5,..\n",
    "# we access their value using .loc command, which get the values for coordinates of the image based on the column it is refering to.\n",
    "# in the first iteration df[i][j-1] would be df[i][0] refering the value in 1st column(x-coordinate) of the image in 'i' row.\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(facialpoints_df['Image'][i],cmap='gray')\n",
    "for j in range(1,31,2):\n",
    "        plt.plot(facialpoints_df.loc[i][j-1], facialpoints_df.loc[i][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Let's view more images in a grid format\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = fig.add_subplot(4, 4, i + 1)    \n",
    "    image = plt.imshow(facialpoints_df['Image'][i], cmap = 'gray')\n",
    "    for j in range(1,31,2):\n",
    "        plt.plot(facialpoints_df.loc[i][j-1], facialpoints_df.loc[i][j], 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new copy of the dataframe\n",
    "import copy\n",
    "facialpoints_df_copy = copy.copy(facialpoints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the header of the DataFrame (names of columns) \n",
    "\n",
    "columns = facialpoints_df_copy.columns[:-1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the pixel values of a sample image and see if it makes sense!\n",
    "facialpoints_df['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample image\n",
    "plt.imshow(facialpoints_df['Image'][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Let's flip the image column horizontally \n",
    "facialpoints_df_copy['Image'] = facialpoints_df_copy['Image'].apply(lambda x: np.flip(x, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take a look at the flipped image and do a sanity check!\n",
    "# Notice that the values of pixels are now flipped\n",
    "facialpoints_df_copy['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are flipping the images horizontally, y coordinate values would be the same\n",
    "# X coordinate values only would need to change, all we have to do is to subtract our initial x-coordinate values from width of the image(96)\n",
    "for i in range(len(columns)):\n",
    "  if i%2 == 0:\n",
    "    facialpoints_df_copy[columns[i]] = facialpoints_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Original image\n",
    "plt.imshow(facialpoints_df['Image'][0],cmap='gray')\n",
    "for j in range(1, 31, 2):\n",
    "        plt.plot(facialpoints_df.loc[0][j-1], facialpoints_df.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original dataframe with the augmented dataframe\n",
    "facialpoints_df_augmented = np.concatenate((facialpoints_df,facialpoints_df_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to perform another image augmentation by randomly increasing images brightness\n",
    "# We multiply pixel values by random values between 1 and 2 to increase the brightness of the image\n",
    "# we clip the value between 0 and 255\n",
    "\n",
    "import random\n",
    "\n",
    "facialpoints_df_copy = copy.copy(facialpoints_df)\n",
    "facialpoints_df_copy['Image'] = facialpoints_df['Image'].apply(lambda x:np.clip(random.uniform(1, 2) * x, 0.0, 255.0))\n",
    "facialpoints_df_augmented = np.concatenate((facialpoints_df_augmented, facialpoints_df_copy))\n",
    "facialpoints_df_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view image with increased brightness\n",
    "\n",
    "plt.imshow(facialpoints_df_copy['Image'][0], cmap = 'gray')\n",
    "for j in range(1, 31, 2):\n",
    "        plt.plot(facialpoints_df_copy.loc[0][j-1], facialpoints_df_copy.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PERFORM NORMALIZATION AND TRAINING DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the value of 'Images' and normalize it\n",
    "# Note that 'Images' are in the 31st column but since indexing start from 0, we refer 31st column by 30\n",
    "img = facialpoints_df_augmented[:, 30]\n",
    "img = img/255.\n",
    "\n",
    "# Create an empty array of shape (10700, 96, 96, 1) to train the model\n",
    "X = np.empty((len(img), 96, 96, 1))\n",
    "\n",
    "# Iterate through the normalized images list and add image values to the empty array \n",
    "# Note that we need to expand it's dimension from (96,96) to (96,96,1)\n",
    "for i in range(len(img)):\n",
    "  X[i,] = np.expand_dims(img[i], axis = 2)\n",
    "\n",
    "# Convert the array type to float32\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the values of key face points coordinates, which are to used as target.\n",
    "y = facialpoints_df_augmented[:,:30]\n",
    "y = np.asarray(y).astype(np.float32)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the values of key face points coordinates, which are to used as target.\n",
    "y = facialpoints_df_augmented[:,:30]\n",
    "y = np.asarray(y).astype(np.float32)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD DEEP RESIDUAL NN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(X, filter, stage):\n",
    "    \n",
    "  # CONVOLUTIONAL BLOCK\n",
    "  X_copy = X\n",
    "  f1 , f2, f3 = filter\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1), strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = MaxPool2D((2,2))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
    "\n",
    "  # Short path\n",
    "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
    "  X_copy = MaxPool2D((2,2))(X_copy)\n",
    "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
    "\n",
    "  # Add data from main and short paths\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    \n",
    "  # IDENTITY BLOCK 1\n",
    "  X_copy = X\n",
    "    \n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
    "\n",
    "  # Add both paths together (Note that we feed the original input as is hence the name \"identity\")\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    \n",
    "  # IDENTITY BLOCK 2\n",
    "  X_copy = X\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
    "\n",
    "  # Add both paths together (Note that we feed the original input as is hence the name \"identity\")\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPILE AND TRAIN DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr = 0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model with least validation loss\n",
    "checkpointer = ModelCheckpoint(filepath = \"weights.hdf5\", verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 256, epochs= 100, validation_split = 0.05, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_json = model.to_json()\n",
    "with open('KeyPointDetector.json', 'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSESS TRAINED MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of training from scratch, you can load trained model weights\n",
    "with open('KeyPointDetector.json', 'r') as json_file:\n",
    "    json_SavedModel = json_file.read()\n",
    "model = tf.keras.models.model_from_json(json_SavedModel)\n",
    "model.load_weights('weights.hdf5')\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model\n",
    "result = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy : {}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction using the testing dataset\n",
    "df_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the rmse loss values\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, df_predict))\n",
    "print(\"RMSE value : {}\".format(rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted values into a dataframe\n",
    "\n",
    "df_predict= pd.DataFrame(df_predict, columns = columns)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test images and their predicted keypoints\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(4, 2, i + 1)\n",
    "    # Using squeeze to convert the image shape from (96,96,1) to (96,96)\n",
    "    plt.imshow(X_test[i].squeeze(),cmap='gray')\n",
    "    for j in range(1,31,2):\n",
    "            plt.plot(df_predict.loc[i][j-1], df_predict.loc[i][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
